{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d54c73-66ed-40e7-a9d6-864d5b637998",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3498db; padding: 10px; border-radius: 10px; text-align: center;\">\n",
    "    <h1 style=\"color: white;\"> Clustering 05 </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c71cd64-6781-47fd-9294-ed313a6c7ffc",
   "metadata": {},
   "source": [
    "# Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c3e2f-857c-4e41-b8ce-2e16a43634b7",
   "metadata": {},
   "source": [
    "Contingency matrix is nothing but the confusion matrix, which we used for evaluating the result of clustering of categorical data. Especially when in the case of unsupervised meachine learning , when y features is not available the significance of contingency matrix is so high as instead of comparing predicted and actual classes, the contingency matrix for clustering compares the clusters assigned by the algorithm to the true (if available) or assumed classes. A confusion matrix is look like ;\n",
    "\n",
    "|                  | Predicted Positive | Predicted Negative |\n",
    "|------------------|--------------------|--------------------|\n",
    "| Actual Positive  |        TP          |        FN          |\n",
    "| Actual Negative  |        FP          |        TN          |\n",
    "\n",
    "where \n",
    "- TP = True Positive\n",
    "- TN = True Negative\n",
    "- FP = False Postive\n",
    "- FN = False Negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db833acf-e0f1-4357-8baa-421249c56994",
   "metadata": {},
   "source": [
    "# Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in certain situations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33441093-42d0-4d0e-95f1-be4d1aeb8760",
   "metadata": {},
   "source": [
    "\n",
    "A pair confusion matrix is a variation of the confusion matrix that is specifically designed for evaluating the performance of binary or two-class classification models. It focuses on pairs of instances rather than individual instances. The pair confusion matrix provides a more detailed breakdown of how the model handles different combinations of instances, particularly in situations where there are dependencies between pairs of instances.\n",
    "\n",
    "|                       | Predicted Positive Pair | Predicted Negative Pair |\n",
    "|-----------------------|-------------------------|-------------------------|\n",
    "| Actual Positive Pair  |           TPP           |           FNP           |\n",
    "| Actual Negative Pair  |           FPP           |           TNP           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e7f40-93be-4c2b-bd3f-9d675e011cb0",
   "metadata": {},
   "source": [
    "# Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically used to evaluate the performance of language models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7aa057-8972-4007-9cb3-5740d40744ee",
   "metadata": {},
   "source": [
    "In the context of natural language processing (NLP), an extrinsic measure evaluates the performance of language models based on their ability to solve real-world tasks or applications, such as sentiment analysis or named entity recognition. Unlike intrinsic measures that focus on specific linguistic properties, extrinsic measures assess a model's practical utility.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92754a47-f741-4924-b82b-f8b919d9d398",
   "metadata": {},
   "source": [
    "# Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an extrinsic measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a4c63-08b2-4d02-9eed-b000f0abf953",
   "metadata": {},
   "source": [
    "In the context of machine learning, intrinsic measures evaluate the performance of a model based on specific characteristics, properties, or components of the model itself. These measures focus on assessing the model's capabilities in isolation, without considering its performance in downstream tasks or real-world applications.\n",
    "\n",
    "On the other hand, extrinsic measures assess the performance of a model in the context of broader, real-world tasks or applications. These measures evaluate how well a model performs in solving practical problems or achieving higher-level goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32fcea6-800f-45c5-89c4-064635b32307",
   "metadata": {},
   "source": [
    "# Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify strengths and weaknesses of a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6e418-b8dd-424c-a0d3-f5c6550718b6",
   "metadata": {},
   "source": [
    "By using these components, you can derive several performance metrics, such as precision, recall, accuracy, and F1 score. Here's how the confusion matrix can help identify strengths and weaknesses of a model:\n",
    "\n",
    "- accuracy ---->  (TP + TN) / (TP + TN + FP + FN)\n",
    "- Precision ----> (TP / (TP + FP))\n",
    "- Recall -------> (TP / (TP + FN))\n",
    "- F1 Score ------>  2 * (precision * recall) / (precision + recall).\n",
    " \n",
    "**High True Positives:** Indicates the model's ability to correctly identify positive instances.\n",
    "\n",
    "**High True Negatives:** Demonstrates the model's proficiency in correctly identifying negative instances.\n",
    "\n",
    "**High False Positives or False Negatives:** Highlights areas where the model may need improvement, depending on the specific requirements of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f0744-ba92-4051-bd12-6bf6a1620994",
   "metadata": {},
   "source": [
    "# Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised learning algorithms, and how can they be interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc53439-0c6e-4e24-9162-42113e264a1d",
   "metadata": {},
   "source": [
    "As we have already discussed the matrics to evaluating the performence of the algorithems. Name of these matrices are above ;\n",
    "- Silheuotte Score\n",
    "- Davies-Bouldin Index\n",
    "- Homogeneity\n",
    "- Completeness\n",
    "- V-measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5bdefd-f7ea-4184-9024-6af19c14c7d7",
   "metadata": {},
   "source": [
    "# Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and how can these limitations be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b1971-e3c1-430c-bcb2-cf1267a79e38",
   "metadata": {},
   "source": [
    "In classification problems, while checking only accuracy of the algorithem and taking the decision on the basis of that accuracy may be dengrious for us. As solely accuracy is not enough to make a perception about the performance of the algorithem. Because there are many other factors which may not affect the accuracy or showing the false accuracy..ie..overfitting, underfittng or imbalanced dataset. Here are the some such problems and their solutions :\n",
    "\n",
    "**Imbalanced dataset :** In datasets where one class significantly outnumbers the others, a model can achieve high accuracy by simply predicting the majority class. It might not be put the imapct on accuracy. To solve this problem we can use alternative matrics such as precision, recall and f1 score. So that we can detect the real performance of the data.\n",
    "\n",
    "**Cost Sensitivity :** In some applications, the cost of misclassifying one class may be higher than misclassifying another. Accuracy does not account for the varying costs associated with different types of errors.To solve this problem we can implement the cost-sensitive learning or customize evaluation metrics based on the specific costs associated with different types of misclassifications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
